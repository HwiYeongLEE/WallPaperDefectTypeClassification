{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "# import cv2\n",
    "from PIL import Image\n",
    "from util import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import torchvision.models as models\n",
    "\n",
    "from transformers import AutoFeatureExtractor, SwinForImageClassification, AutoImageProcessor, Trainer, TrainingArguments\n",
    "\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc497f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=WallPaperDefectTypeClassification\n",
      "env: WANDB_NOTEBOOK_NAME=./baseline.ipynb\n",
      "env: WANDB_LOG_MODEL=end\n",
      "env: WANDB_WATCH=all\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=WallPaperDefectTypeClassification\n",
    "%env WANDB_NOTEBOOK_NAME=./baseline.ipynb\n",
    "%env WANDB_LOG_MODEL=end\n",
    "%env WANDB_WATCH=all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13862e3-bb27-47af-9b58-a9fbf804df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':5,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':8,\n",
    "    'WEIGHT_DECAY':0.01,\n",
    "    'WARMUP_RATIO':0.1,\n",
    "    'SEED':42,\n",
    "    'NUM_WORKERS':2,\n",
    "    'PRETRAINED_MODEL': \"microsoft/swin-tiny-patch4-window7-224\",\n",
    "    'MODEL_VER' : \"0.0.2\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
   "metadata": {},
   "source": [
    "## Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_list = glob.glob('../data/train/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4119733d-adef-436c-afca-4112a9225d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "df['label'] = df['img_path'].apply(lambda x: str(x).split('/')[-2]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db41c93-3515-4fcd-936b-0a01f5388b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1f117e-105d-4e9e-b9bd-938d4271a940",
   "metadata": {},
   "source": [
    "## Label-Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c8c5916-8065-4b5c-aa37-f3fb2b9fa422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# le = preprocessing.LabelEncoder()\n",
    "# train['label'] = le.fit_transform(train['label'])\n",
    "# val['label'] = le.transform(val['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {},
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89de0063",
   "metadata": {},
   "source": [
    "<img src=https://d2.naver.com/content/images/2021/01/efbe9400-5214-11eb-9c67-30fab62770ec.png>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "085f7f5e",
   "metadata": {},
   "source": [
    "**Albumentation Tutorials**<br>\n",
    "https://github.com/albumentations-team/albumentations_examples/blob/master/notebooks/migrating_from_torchvision_to_albumentations.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None, processor=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        self.processor = processor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_path = self.img_path_list[index]\n",
    "        image = Image.open(img_path)\n",
    "        image_tr = self.transforms(image=np.array(image))['image']\n",
    "        pixel_values = self.processor(image_tr, return_tensors=\"pt\").pixel_values.squeeze()\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return {\n",
    "                'pixel_values': pixel_values, \n",
    "                'label': label,\n",
    "                }\n",
    "        else:\n",
    "            return {\n",
    "                'pixel_values': pixel_values,\n",
    "                }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340b4a8b-5d6c-413f-b8b6-066e91a660e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.HorizontalFlip(p=0.5),\n",
    "                            A.RandomBrightnessContrast(p=0.5),\n",
    "                            A.RandomScale(scale_limit=0.1, p=0.5),\n",
    "                            A.RandomCropFromBorders(p=0.5),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            # Augmentations\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "281c81d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = CFG['PRETRAINED_MODEL']\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d880481-1965-499d-9caa-fdfa8526f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\n",
    "    train['img_path'].values, train['label'].values, train_transform, image_processor)\n",
    "\n",
    "val_dataset = CustomDataset(\n",
    "    val['img_path'].values, val['label'].values, test_transform, image_processor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39962463-032f-490a-a76d-c03991795f38",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b33dcfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"../data/map.csv\")['Categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0267ef47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-tiny-patch4-window7-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([19, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([19]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 1707 MB.\n"
     ]
    }
   ],
   "source": [
    "model = SwinForImageClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)},\n",
    "    ignore_mismatched_sizes=True,\n",
    ").to(device)\n",
    "\n",
    "print_gpu_utilization()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b82cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "  return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e4f9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['label'] for x in batch]).type(torch.LongTensor),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24435d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric' : {\n",
    "        'name': 'eval/f1',\n",
    "        'goal': 'maximize'   \n",
    "        },\n",
    "    'parameters' : {\n",
    "        'learning_rate': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 1e-5,\n",
    "            'max': 1e-3\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'values': [0.0, 0.1, 0.2, 0.3]\n",
    "        },\n",
    "        'warmup_ratio':{\n",
    "            'values': [0.0, 0.1, 0.2]\n",
    "        },\n",
    "        'lr_scheduler_type':{\n",
    "            'values': ['linear', 'cosine']\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "589dd1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: iqe2ogyw\n",
      "Sweep URL: https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/iqe2ogyw\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=os.environ['WANDB_PROJECT'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30d94ecf",
   "metadata": {},
   "source": [
    "```\n",
    "class SchedulerType(ExplicitEnum):\n",
    "    LINEAR = \"linear\"\n",
    "    COSINE = \"cosine\"\n",
    "    COSINE_WITH_RESTARTS = \"cosine_with_restarts\"\n",
    "    POLYNOMIAL = \"polynomial\"\n",
    "    CONSTANT = \"constant\"\n",
    "    CONSTANT_WITH_WARMUP = \"constant_with_warmup\"\n",
    "    INVERSE_SQRT = \"inverse_sqrt\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9cb3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        args = TrainingArguments(\n",
    "            output_dir=f\"../outputs/{model_name}-finetuned\",\n",
    "            overwrite_output_dir=True,\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=config.learning_rate,\n",
    "            per_device_train_batch_size=CFG['BATCH_SIZE'],\n",
    "            per_device_eval_batch_size=CFG['BATCH_SIZE'],\n",
    "            num_train_epochs=CFG['EPOCHS'],\n",
    "            weight_decay=config.weight_decay,\n",
    "            logging_steps=10,\n",
    "            gradient_accumulation_steps=4,\n",
    "            dataloader_num_workers=CFG['NUM_WORKERS'],\n",
    "            warmup_ratio=config.warmup_ratio,\n",
    "            fp16=True,\n",
    "            lr_scheduler_type=config.lr_scheduler_type,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            run_name='v.'+CFG['MODEL_VER'],\n",
    "            report_to='wandb',\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            data_collator=collate_fn,\n",
    "            compute_metrics=compute_metrics,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            tokenizer=image_processor,\n",
    "        )\n",
    "\n",
    "        trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "407e4c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kux3rl86 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 7.946814763316721e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: linear\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m2gnldud\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hylee/repo/WallPaperDefectTypeClassification/notebook/wandb/run-20230426_005322-kux3rl86</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/kux3rl86' target=\"_blank\">atomic-sweep-1</a></strong> to <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/iqe2ogyw' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/iqe2ogyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/iqe2ogyw' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/iqe2ogyw</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/kux3rl86' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/kux3rl86</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_scheduler_type' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 76/375 00:21 < 01:25, 3.48 it/s, Epoch 0.99/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  4/130 00:00 < 00:04, 27.06 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁▅▇▇█</td></tr><tr><td>eval/loss</td><td>█▃▂▁▁</td></tr><tr><td>eval/runtime</td><td>▁▃▄▆█</td></tr><tr><td>eval/samples_per_second</td><td>█▆▅▃▁</td></tr><tr><td>eval/steps_per_second</td><td>█▆▅▃▁</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>███▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▄▄▃▄▃▂▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.8581</td></tr><tr><td>eval/loss</td><td>0.51384</td></tr><tr><td>eval/runtime</td><td>6.7177</td></tr><tr><td>eval/samples_per_second</td><td>154.518</td></tr><tr><td>eval/steps_per_second</td><td>19.352</td></tr><tr><td>train/epoch</td><td>4.95</td></tr><tr><td>train/global_step</td><td>375</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/loss</td><td>0.2051</td></tr><tr><td>train/total_flos</td><td>2.979161972914176e+17</td></tr><tr><td>train/train_loss</td><td>0.56712</td></tr><tr><td>train/train_runtime</td><td>149.575</td></tr><tr><td>train/train_samples_per_second</td><td>80.862</td></tr><tr><td>train/train_steps_per_second</td><td>2.507</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">atomic-sweep-1</strong> at: <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/kux3rl86' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/kux3rl86</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230426_005322-kux3rl86/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vaw98xsp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00013260491325986333\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: linear\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=10)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b2fdbeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run confused-sweep-3 with 0.8607638734588623% validation accuracy\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 404: Not Found)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/wandb/sdk/lib/retry.py:131\u001b[0m, in \u001b[0;36mRetry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 131\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    132\u001b[0m     \u001b[39m# Only print resolved attempts once every minute\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/wandb/apis/public.py:2822\u001b[0m, in \u001b[0;36mFile.download\u001b[0;34m(self, root, replace, exist_ok)\u001b[0m\n\u001b[1;32m   2818\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2819\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFile already exists, pass replace=True to overwrite or exist_ok=True to leave it as is and don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt error.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2820\u001b[0m         )\n\u001b[0;32m-> 2822\u001b[0m util\u001b[39m.\u001b[39;49mdownload_file_from_url(path, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49murl, Api()\u001b[39m.\u001b[39;49mapi_key)\n\u001b[1;32m   2823\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mopen\u001b[39m(path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/wandb/util.py:1271\u001b[0m, in \u001b[0;36mdownload_file_from_url\u001b[0;34m(dest_path, source_url, api_key)\u001b[0m\n\u001b[1;32m   1270\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(source_url, auth\u001b[39m=\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mapi\u001b[39m\u001b[39m\"\u001b[39m, api_key), stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, timeout\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 1271\u001b[0m response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m   1273\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39msep \u001b[39min\u001b[39;00m dest_path:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.wandb.ai/files/2gnldud/WallPaperDefectTypeClassification/b5z8yyph/model.h5",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m val_f1 \u001b[39m=\u001b[39m runs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39msummary\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39meval/f1\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest run \u001b[39m\u001b[39m{\u001b[39;00mruns[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m with \u001b[39m\u001b[39m{\u001b[39;00mval_f1\u001b[39m}\u001b[39;00m\u001b[39m% validation accuracy\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m runs[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mfile(\u001b[39m\"\u001b[39;49m\u001b[39mmodel.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mdownload(replace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest model saved to model-best.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/wandb/apis/normalize.py:73\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[39mraise\u001b[39;00m CommError(message, err\u001b[39m.\u001b[39mlast_exception)\u001b[39m.\u001b[39mwith_traceback(\n\u001b[1;32m     70\u001b[0m             sys\u001b[39m.\u001b[39mexc_info()[\u001b[39m2\u001b[39m]\n\u001b[1;32m     71\u001b[0m         )\n\u001b[1;32m     72\u001b[0m \u001b[39mexcept\u001b[39;00m Error \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m---> 73\u001b[0m     \u001b[39mraise\u001b[39;00m err\n\u001b[1;32m     74\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m     75\u001b[0m     \u001b[39m# gql raises server errors with dict's as strings...\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(err\u001b[39m.\u001b[39margs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/wandb/apis/normalize.py:41\u001b[0m, in \u001b[0;36mnormalize_exceptions.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m message \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mWhoa, you found a bug.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     40\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     42\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mHTTPError \u001b[39mas\u001b[39;00m error:\n\u001b[1;32m     43\u001b[0m     errors \u001b[39m=\u001b[39m parse_backend_error_messages(error\u001b[39m.\u001b[39mresponse)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/wandb/sdk/lib/retry.py:212\u001b[0m, in \u001b[0;36mretriable.<locals>.decorator.<locals>.wrapped_fn\u001b[0;34m(*args, **kargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(fn)\n\u001b[1;32m    211\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m--> 212\u001b[0m     \u001b[39mreturn\u001b[39;00m retrier(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/wandb/sdk/lib/retry.py:147\u001b[0m, in \u001b[0;36mRetry.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[1;32m    145\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retryable_exceptions \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    146\u001b[0m     \u001b[39m# if the secondary check fails, re-raise\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m     retry_timedelta_triggered \u001b[39m=\u001b[39m check_retry_fn(e)\n\u001b[1;32m    148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m retry_timedelta_triggered:\n\u001b[1;32m    149\u001b[0m         \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/wandb/util.py:892\u001b[0m, in \u001b[0;36mno_retry_auth\u001b[0;34m(e)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[39mraise\u001b[39;00m CommError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPermission denied to access \u001b[39m\u001b[39m{\u001b[39;00mwandb\u001b[39m.\u001b[39mrun\u001b[39m.\u001b[39mpath\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    891\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 892\u001b[0m     \u001b[39mraise\u001b[39;00m CommError(\n\u001b[1;32m    893\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt appears that you do not have permission to access the requested resource. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    894\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mPlease reach out to the project owner to grant you access. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    895\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIf you have the correct permissions, verify that there are no issues with your networking setup.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    896\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(Error \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mreason\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    897\u001b[0m     )\n",
      "\u001b[0;31mCommError\u001b[0m: It appears that you do not have permission to access the requested resource. Please reach out to the project owner to grant you access. If you have the correct permissions, verify that there are no issues with your networking setup.(Error 404: Not Found)"
     ]
    }
   ],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "sweep = api.sweep(f\"2gnldud/WallPaperDefectTypeClassification/{sweep_id}\")\n",
    "runs = sorted(sweep.runs,\n",
    "  key=lambda run: run.summary.get(\"eval/f1\", 0), reverse=True)\n",
    "val_f1 = runs[0].summary.get(\"eval/f1\", 0)\n",
    "print(f\"Best run {runs[0].name} with {val_f1}% validation accuracy\")\n",
    "\n",
    "runs[0].file(\"model.h5\").download(replace=True)\n",
    "print(\"Best model saved to model-best.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47827bd5",
   "metadata": {},
   "source": [
    "trainer.save_model(f\"../models/v.{CFG['MODEL_VER']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d303dfa0",
   "metadata": {},
   "source": [
    "metrics = trainer.evaluate()\n",
    "# some nice to haves:\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00228365",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71950c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('../data/test.csv')\n",
    "test['img_path'] = test['img_path'].apply(lambda x: str(x).replace(\"./\", \"../data/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "45d1b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test['img_path'].values, None, test_transform, image_processor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=CFG['NUM_WORKERS'])\n",
    "infer_model = SwinForImageClassification.from_pretrained(f\"../models/v.{CFG['MODEL_VER']}\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "296ca5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs in tqdm(iter(test_loader)):\n",
    "            inputs['pixel_values'] = inputs['pixel_values'].to(device)\n",
    "            logits = model(**inputs).logits\n",
    "            predicted_label = torch.argmax(logits, dim=-1).tolist()\n",
    "            \n",
    "            preds += [model.config.id2label[x] for x in predicted_label]\n",
    "            \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e4e7314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59ee2f7666a4a159542177289f1c344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/198 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds = inference(infer_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be19990d",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc04aa39",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ecbcbcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['label'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db83a327",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv(f\"../submissions/submit_v.{CFG['MODEL_VER']}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec323ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
