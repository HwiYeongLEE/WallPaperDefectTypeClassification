{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "from PIL import Image\n",
    "from util import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from transformers import SwinForImageClassification, AutoImageProcessor, Trainer, TrainingArguments\n",
    "\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f949930f",
   "metadata": {},
   "source": [
    "## Define Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fc497f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=WallPaperDefectTypeClassification\n",
      "env: WANDB_NOTEBOOK_NAME=./experiment.ipynb\n",
      "env: WANDB_LOG_MODEL=end\n",
      "env: WANDB_WATCH=all\n",
      "env: WANDB_RUN_GROUP=exp0\n",
      "env: WANDB_JOB_TYPE=train\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=WallPaperDefectTypeClassification\n",
    "%env WANDB_NOTEBOOK_NAME=./experiment.ipynb\n",
    "%env WANDB_LOG_MODEL=end\n",
    "%env WANDB_WATCH=all\n",
    "%env WANDB_RUN_GROUP=exp0\n",
    "%env WANDB_JOB_TYPE=train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d13862e3-bb27-47af-9b58-a9fbf804df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device.type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE':224,\n",
    "    'EPOCHS':10,\n",
    "    'LEARNING_RATE':3e-4,\n",
    "    'BATCH_SIZE':8,\n",
    "    'WEIGHT_DECAY':0.01,\n",
    "    'WARMUP_RATIO':0.1,\n",
    "    'SEED':42,\n",
    "    'NUM_WORKERS':4,\n",
    "    'PRETRAINED_MODEL': \"microsoft/swin-base-patch4-window7-224-in22k\",\n",
    "    'MODEL_VER' : \"0.0.3_tiny+default A\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
   "metadata": {},
   "source": [
    "## Fixed RandomSeed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED']) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_img_list = glob.glob('../data/train/*/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4119733d-adef-436c-afca-4112a9225d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['img_path', 'label'])\n",
    "df['img_path'] = all_img_list\n",
    "df['label'] = df['img_path'].apply(lambda x: str(x).split('/')[-2]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4db41c93-3515-4fcd-936b-0a01f5388b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
   "metadata": {},
   "source": [
    "## CustomDataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "89de0063",
   "metadata": {},
   "source": [
    "<img src=https://d2.naver.com/content/images/2021/01/efbe9400-5214-11eb-9c67-30fab62770ec.png>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "085f7f5e",
   "metadata": {},
   "source": [
    "**Albumentation Tutorials**<br>\n",
    "https://github.com/albumentations-team/albumentations_examples/blob/master/notebooks/migrating_from_torchvision_to_albumentations.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_path_list, label_list, transforms=None, processor=None):\n",
    "        self.img_path_list = img_path_list\n",
    "        self.label_list = label_list\n",
    "        self.transforms = transforms\n",
    "        self.processor = processor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        img_path = self.img_path_list[index]\n",
    "        image = Image.open(img_path)\n",
    "        image_tr = self.transforms(image=np.array(image))['image']\n",
    "        pixel_values = self.processor(image_tr, return_tensors=\"pt\").pixel_values.squeeze()\n",
    "        \n",
    "        if self.label_list is not None:\n",
    "            label = self.label_list[index]\n",
    "            return {\n",
    "                'pixel_values': pixel_values, \n",
    "                'label': label,\n",
    "                }\n",
    "        else:\n",
    "            return {\n",
    "                'pixel_values': pixel_values,\n",
    "                }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "340b4a8b-5d6c-413f-b8b6-066e91a660e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "                            A.HorizontalFlip(p=0.5),\n",
    "                            A.RandomBrightnessContrast(p=0.5),\n",
    "                            A.RandomScale(scale_limit=0.1, p=0.5),\n",
    "                            A.RandomCropFromBorders(p=0.5),\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                            # Augmentations\n",
    "                            ToTensorV2()\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "281c81d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = CFG['PRETRAINED_MODEL']\n",
    "image_processor = AutoImageProcessor.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d880481-1965-499d-9caa-fdfa8526f789",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(\n",
    "    train['img_path'].values, train['label'].values, train_transform, image_processor)\n",
    "\n",
    "val_dataset = CustomDataset(\n",
    "    val['img_path'].values, val['label'].values, test_transform, image_processor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39962463-032f-490a-a76d-c03991795f38",
   "metadata": {},
   "source": [
    "## Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0267ef47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    labels = pd.read_csv(\"../data/map.csv\")['Categories']\n",
    "    model = SwinForImageClassification.from_pretrained(\n",
    "        model_checkpoint,\n",
    "        num_labels=len(labels),\n",
    "        id2label={str(i): c for i, c in enumerate(labels)},\n",
    "        label2id={c: str(i) for i, c in enumerate(labels)},\n",
    "        ignore_mismatched_sizes=True,\n",
    "    ).to(device)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b82cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"f1\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "  return metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids, average='weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e4f9c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
    "        'labels': torch.tensor([x['label'] for x in batch]).type(torch.LongTensor),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24435d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric' : {\n",
    "        'name': 'eval/f1',\n",
    "        'goal': 'maximize'   \n",
    "        },\n",
    "    'parameters' : {\n",
    "        'learning_rate': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 1e-5,\n",
    "            'max': 1e-3\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'distribution': 'q_uniform',\n",
    "            'min': 0,\n",
    "            'max': 1e-2,\n",
    "            'q': 0.001\n",
    "        },\n",
    "        'warmup_ratio':{\n",
    "            'values': [0.0, 0.1, 0.2]\n",
    "        },\n",
    "        'lr_scheduler_type':{\n",
    "            'values': ['linear', 'cosine']\n",
    "        },\n",
    "        'batch_size':{\n",
    "            'values': 32\n",
    "        }\n",
    "    },\n",
    "    'early_terminate': {\n",
    "        'type': 'hyperband',\n",
    "        'min_iter': 3,\n",
    "        'eta' : 2\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "589dd1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: cftsawev\n",
      "Sweep URL: https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=os.environ['WANDB_PROJECT'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30d94ecf",
   "metadata": {},
   "source": [
    "```\n",
    "class SchedulerType(ExplicitEnum):\n",
    "    LINEAR = \"linear\"\n",
    "    COSINE = \"cosine\"\n",
    "    COSINE_WITH_RESTARTS = \"cosine_with_restarts\"\n",
    "    POLYNOMIAL = \"polynomial\"\n",
    "    CONSTANT = \"constant\"\n",
    "    CONSTANT_WITH_WARMUP = \"constant_with_warmup\"\n",
    "    INVERSE_SQRT = \"inverse_sqrt\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9cb3a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        args = TrainingArguments(\n",
    "            output_dir=f\"../outputs/{model_name}-finetuned\",\n",
    "            overwrite_output_dir=True,\n",
    "            remove_unused_columns=False,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            save_strategy=\"epoch\",\n",
    "            learning_rate=config.learning_rate,\n",
    "            per_device_train_batch_size=config.batch_size,\n",
    "            per_device_eval_batch_size=config.batch_size,\n",
    "            num_train_epochs=CFG['EPOCHS'],\n",
    "            weight_decay=config.weight_decay,\n",
    "            logging_steps=10,\n",
    "            gradient_accumulation_steps=4,\n",
    "            dataloader_num_workers=CFG['NUM_WORKERS'],\n",
    "            warmup_ratio=config.warmup_ratio,\n",
    "            fp16=True,\n",
    "            lr_scheduler_type=config.lr_scheduler_type,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1\",\n",
    "            run_name='v.'+CFG['MODEL_VER'],\n",
    "            report_to='wandb',\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model_init=model_init,\n",
    "            args=args,\n",
    "            data_collator=collate_fn,\n",
    "            compute_metrics=compute_metrics,\n",
    "            train_dataset=train_dataset,\n",
    "            eval_dataset=val_dataset,\n",
    "            tokenizer=image_processor,\n",
    "        )\n",
    "\n",
    "        trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "407e4c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: em7zogky with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0002738450494723399\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: constant_with_warmup\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.002\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m2gnldud\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hylee/repo/WallPaperDefectTypeClassification/notebook/wandb/run-20230428_164852-em7zogky</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/em7zogky' target=\"_blank\">effortless-sweep-1</a></strong> to <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/em7zogky' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/em7zogky</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-base-patch4-window7-224-in22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 1024]) in the checkpoint and torch.Size([19, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([19]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-base-patch4-window7-224-in22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 1024]) in the checkpoint and torch.Size([19, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([19]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_scheduler_type' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='96' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 96/190 03:21 < 03:21, 0.47 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.283100</td>\n",
       "      <td>0.926181</td>\n",
       "      <td>0.717421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.757500</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.797939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.395800</td>\n",
       "      <td>0.494081</td>\n",
       "      <td>0.846583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.247400</td>\n",
       "      <td>0.700539</td>\n",
       "      <td>0.809256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='32' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [32/33 00:06 < 00:00, 5.12 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁▅█▆▆▇▇█▆▇</td></tr><tr><td>eval/loss</td><td>█▃▁▄▄▄▄▃▆▆</td></tr><tr><td>eval/runtime</td><td>▂▅▆█▄▁▃▃▃▃</td></tr><tr><td>eval/samples_per_second</td><td>▆▃▂▁▄█▅▅▅▅</td></tr><tr><td>eval/steps_per_second</td><td>▆▃▂▁▄█▅▅▅▅</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▄▄▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>▁██████████████████</td></tr><tr><td>train/loss</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.83025</td></tr><tr><td>eval/loss</td><td>0.79686</td></tr><tr><td>eval/runtime</td><td>6.0702</td></tr><tr><td>eval/samples_per_second</td><td>170.998</td></tr><tr><td>eval/steps_per_second</td><td>5.436</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>190</td></tr><tr><td>train/learning_rate</td><td>0.00027</td></tr><tr><td>train/loss</td><td>0.145</td></tr><tr><td>train/total_flos</td><td>1.89555968566315e+18</td></tr><tr><td>train/train_loss</td><td>0.39893</td></tr><tr><td>train/train_runtime</td><td>421.4844</td></tr><tr><td>train/train_samples_per_second</td><td>57.392</td></tr><tr><td>train/train_steps_per_second</td><td>0.451</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">effortless-sweep-1</strong> at: <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/em7zogky' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/em7zogky</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230428_164852-em7zogky/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bnnymapk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 16\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 4.944008967957393e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: constant_with_warmup\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.009000000000000001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hylee/repo/WallPaperDefectTypeClassification/notebook/wandb/run-20230428_165633-bnnymapk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/bnnymapk' target=\"_blank\">copper-sweep-2</a></strong> to <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/bnnymapk' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/bnnymapk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-base-patch4-window7-224-in22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 1024]) in the checkpoint and torch.Size([19, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([19]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-base-patch4-window7-224-in22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 1024]) in the checkpoint and torch.Size([19, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([19]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_scheduler_type' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='380' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/380 01:38 < 04:23, 1.05 it/s, Epoch 2.74/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.120700</td>\n",
       "      <td>0.765339</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.603500</td>\n",
       "      <td>0.624480</td>\n",
       "      <td>0.788722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁▃▇▇▇██▆▇▇</td></tr><tr><td>eval/loss</td><td>█▅▁▂▁▂▃▅▅▅</td></tr><tr><td>eval/runtime</td><td>██▇▁▂▆▇▆▆▁</td></tr><tr><td>eval/samples_per_second</td><td>▁▁▂▇▇▂▂▂▃█</td></tr><tr><td>eval/steps_per_second</td><td>▁▁▂▇▇▂▂▂▃█</td></tr><tr><td>train/epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/global_step</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>train/learning_rate</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/total_flos</td><td>▁</td></tr><tr><td>train/train_loss</td><td>▁</td></tr><tr><td>train/train_runtime</td><td>▁</td></tr><tr><td>train/train_samples_per_second</td><td>▁</td></tr><tr><td>train/train_steps_per_second</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.8629</td></tr><tr><td>eval/loss</td><td>0.62859</td></tr><tr><td>eval/runtime</td><td>4.0464</td></tr><tr><td>eval/samples_per_second</td><td>256.525</td></tr><tr><td>eval/steps_per_second</td><td>16.064</td></tr><tr><td>train/epoch</td><td>10.0</td></tr><tr><td>train/global_step</td><td>380</td></tr><tr><td>train/learning_rate</td><td>5e-05</td></tr><tr><td>train/loss</td><td>0.0339</td></tr><tr><td>train/total_flos</td><td>1.89555968566315e+18</td></tr><tr><td>train/train_loss</td><td>0.29925</td></tr><tr><td>train/train_runtime</td><td>361.4083</td></tr><tr><td>train/train_samples_per_second</td><td>66.933</td></tr><tr><td>train/train_steps_per_second</td><td>1.051</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-sweep-2</strong> at: <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/bnnymapk' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/bnnymapk</a><br/>Synced 6 W&B file(s), 0 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230428_165633-bnnymapk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9vs9l3uv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.628883109956865e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: linear\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.004\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hylee/repo/WallPaperDefectTypeClassification/notebook/wandb/run-20230428_170308-9vs9l3uv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/9vs9l3uv' target=\"_blank\">solar-sweep-3</a></strong> to <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/sweeps/cftsawev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/9vs9l3uv' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/9vs9l3uv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-base-patch4-window7-224-in22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 1024]) in the checkpoint and torch.Size([19, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([19]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of SwinForImageClassification were not initialized from the model checkpoint at microsoft/swin-base-patch4-window7-224-in22k and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([21841, 1024]) in the checkpoint and torch.Size([19, 1024]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([21841]) in the checkpoint and torch.Size([19]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'learning_rate' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'weight_decay' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'lr_scheduler_type' was locked by 'sweep' (ignored update).\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Config item 'warmup_ratio' was locked by 'sweep' (ignored update).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21' max='190' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 21/190 00:38 < 05:46, 0.49 it/s, Epoch 1.05/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.423300</td>\n",
       "      <td>1.552098</td>\n",
       "      <td>0.458652</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8ff0a62ce44eda94e11c2c1ca8ec4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>▁</td></tr><tr><td>eval/loss</td><td>▁</td></tr><tr><td>eval/runtime</td><td>▁</td></tr><tr><td>eval/samples_per_second</td><td>▁</td></tr><tr><td>eval/steps_per_second</td><td>▁</td></tr><tr><td>train/epoch</td><td>▁█</td></tr><tr><td>train/global_step</td><td>▁█</td></tr><tr><td>train/learning_rate</td><td>▁</td></tr><tr><td>train/loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/f1</td><td>0.45865</td></tr><tr><td>eval/loss</td><td>1.5521</td></tr><tr><td>eval/runtime</td><td>8.3591</td></tr><tr><td>eval/samples_per_second</td><td>124.177</td></tr><tr><td>eval/steps_per_second</td><td>3.948</td></tr><tr><td>train/epoch</td><td>1.0</td></tr><tr><td>train/global_step</td><td>19</td></tr><tr><td>train/learning_rate</td><td>2e-05</td></tr><tr><td>train/loss</td><td>2.4233</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">solar-sweep-3</strong> at: <a href='https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/9vs9l3uv' target=\"_blank\">https://wandb.ai/2gnldud/WallPaperDefectTypeClassification/runs/9vs9l3uv</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230428_170308-9vs9l3uv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train, count=16)\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
